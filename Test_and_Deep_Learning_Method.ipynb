{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0s5evL5zo2s8"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install scaper\n",
        "!pip install nussl\n",
        "!pip install git+https://github.com/source-separation/tutorial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CtQt_C7zo2s-"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "from common import data, viz\n",
        "import nussl\n",
        "# Prepare MUSDB\n",
        "data.prepare_musdb('~/.nussl/tutorial/')\n",
        "\n",
        "import nussl\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "def visualize_and_embed(sources):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.subplot(211)\n",
        "    nussl.utils.visualize_sources_as_masks(sources,\n",
        "        y_axis='mel', db_cutoff=-60, alpha_amount=2.0)\n",
        "    plt.subplot(212)\n",
        "    nussl.utils.visualize_sources_as_waveform(\n",
        "        sources, show_legend=False)\n",
        "    plt.show()\n",
        "    nussl.play_utils.multitrack(sources)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from nussl.datasets import transforms as nussl_tfm\n",
        "tfm = nussl_tfm.Compose([\n",
        "    nussl_tfm.SumSources([['bass', 'drums', 'other']]),\n",
        "])\n",
        "test_dataset = nussl.datasets.MUSDB18(subsets=['test'], transform=tfm)\n"
      ],
      "metadata": {
        "id": "DEuLvJmFpEtg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test REPET "
      ],
      "metadata": {
        "id": "0OwrB70rRupV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_mask_with_noisy_phase(mix_stft, mask):\n",
        "    mix_magnitude, mix_phase = np.abs(mix_stft), np.angle(mix_stft)\n",
        "    src_magnitude = mix_magnitude * mask\n",
        "    src_stft = src_magnitude * np.exp(1j * mix_phase)\n",
        "    return src_stft\n"
      ],
      "metadata": {
        "id": "hfC1J8f9tCyu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "output_folder = Path('.').absolute()"
      ],
      "metadata": {
        "id": "dROc2KD6vcry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Just do 5 items for speed. Change to 50 for actual experiment.\n",
        "for i in range(50):\n",
        "    item = test_dataset[i]\n",
        "    mix = item['mix']\n",
        "    repet = nussl.separation.primitive.Repet(item['mix'])\n",
        "\n",
        "    # Background and Foreground Masks\n",
        "    bg_mask, fg_mask = repet.run()\n",
        "    bg_mask_arr = bg_mask.mask\n",
        "    fg_mask_arr = fg_mask.mask\n",
        "    mix.stft()\n",
        "    bg_stft = apply_mask_with_noisy_phase(mix.stft_data, bg_mask_arr)\n",
        "    fg_stft = apply_mask_with_noisy_phase(mix.stft_data, fg_mask_arr)\n",
        "\n",
        "\n",
        "      # Make new AudioSignals for background and foreground with phase\n",
        "    bg_phase = mix.make_copy_with_stft_data(bg_stft)\n",
        "    a = bg_phase.istft()\n",
        "    fg_phase = mix.make_copy_with_stft_data(fg_stft)\n",
        "    b = fg_phase.istft()\n",
        "\n",
        "    source_keys = list(item['sources'].keys())\n",
        "    estimates = {\n",
        "        'vocals': fg_phase,\n",
        "        'bass+drums+other': bg_phase\n",
        "    }\n",
        "\n",
        "    sources = [item['sources'][k] for k in source_keys]\n",
        "    estimates = [estimates[k] for k in source_keys]\n",
        "\n",
        "    evaluator = nussl.evaluation.BSSEvalScale(\n",
        "        sources, estimates, source_labels=source_keys\n",
        "    )\n",
        "    scores = evaluator.evaluate()\n",
        "    output_folder = Path(output_folder).absolute()\n",
        "    output_folder.mkdir(exist_ok=True)\n",
        "    output_file = output_folder / sources[0].file_name.replace('wav', 'json')\n",
        "    with open(output_file, 'w') as f:\n",
        "        json.dump(scores, f, indent=4)"
      ],
      "metadata": {
        "id": "whorjR9Mr4-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import numpy as np\n",
        "\n",
        "json_files = glob.glob(f\"*.json\")\n",
        "df = nussl.evaluation.aggregate_score_files(\n",
        "    json_files, aggregator=np.nanmedian)\n",
        "nussl.evaluation.associate_metrics(repet, df, test_dataset)\n",
        "report_card = nussl.evaluation.report_card(\n",
        "    df, report_each_source=True)\n",
        "print(report_card)"
      ],
      "metadata": {
        "id": "EN58zitLv2Bf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "item = test_dataset[0]\n",
        "mix = item['mix']\n",
        "repet = nussl.separation.primitive.Repet(item['mix'])\n",
        "\n",
        "# Background and Foreground Masks\n",
        "bg_mask, fg_mask = repet.run()\n",
        "bg_mask_arr = bg_mask.mask\n",
        "fg_mask_arr = fg_mask.mask\n",
        "mix.stft()\n",
        "bg_stft = apply_mask_with_noisy_phase(mix.stft_data, bg_mask_arr)\n",
        "fg_stft = apply_mask_with_noisy_phase(mix.stft_data, fg_mask_arr)\n",
        "\n",
        "\n",
        "  # Make new AudioSignals for background and foreground with phase\n",
        "bg_phase = mix.make_copy_with_stft_data(bg_stft)\n",
        "a = bg_phase.istft()\n",
        "fg_phase = mix.make_copy_with_stft_data(fg_stft)\n",
        "b = fg_phase.istft()\n",
        "bg_phase.embed_audio()\n",
        "# fg_phase.embed_audio()"
      ],
      "metadata": {
        "id": "LIesHCamwB1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "item['mix'].embed_audio()"
      ],
      "metadata": {
        "id": "2V3rEC-cH-jh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TEST HPSS"
      ],
      "metadata": {
        "id": "Zuj5lkpRRyvH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyHPSS(nussl.separation.base.MaskSeparationBase):\n",
        "    \n",
        "    def __init__(self, audio_signal, kernel_size=31, mask_type='soft',\n",
        "                 mask_threshold=0.5):\n",
        "        \"\"\"Setup code goes here.\"\"\"\n",
        "        \n",
        "        # The super class will save all of these attributes for us.\n",
        "        super().__init__(\n",
        "            input_audio_signal=audio_signal, \n",
        "            mask_type=mask_type,\n",
        "            mask_threshold=mask_threshold\n",
        "        )\n",
        "        \n",
        "        # Save the kernel size.\n",
        "        self.kernel_size = kernel_size\n",
        "        \n",
        "    def run(self):\n",
        "        \"\"\"Code for running HPSS. Returns masks.\"\"\"\n",
        "        \n",
        "        # Keep a list of each mask type.\n",
        "        harmonic_masks = []\n",
        "        percussive_masks = []\n",
        "\n",
        "        # Our signal might have more than one channel:\n",
        "        # Apply HPSS to each channel individually.\n",
        "        for ch in range(self.audio_signal.num_channels):\n",
        "            # apply mask\n",
        "            harmonic_mask, percussive_mask = librosa.decompose.hpss(\n",
        "                self.stft[:, :, ch], kernel_size=self.kernel_size, mask=True)\n",
        "            harmonic_masks.append(harmonic_mask)\n",
        "            percussive_masks.append(percussive_mask)\n",
        "\n",
        "        # Order the masks correctly.\n",
        "        harmonic_masks = np.stack(harmonic_masks, axis=-1)\n",
        "        percussive_masks = np.stack(percussive_masks, axis=-1)\n",
        "        _masks = np.stack([harmonic_masks, percussive_masks], axis=-1)\n",
        "        \n",
        "        # Convert the masks to `nussl.MaskBase` types.\n",
        "        self.result_masks = []\n",
        "        for i in range(_masks.shape[-1]):\n",
        "            mask_data = _masks[..., i]\n",
        "            if self.mask_type == self.MASKS['binary']:\n",
        "                mask_data = _masks[..., i] == np.max(_masks, axis=-1)\n",
        "            mask = self.mask_type(mask_data)\n",
        "            self.result_masks.append(mask)\n",
        "\n",
        "        # Return the masks>\n",
        "        return self.result_masks\n",
        "        "
      ],
      "metadata": {
        "id": "Ywzjef5bw5qu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa"
      ],
      "metadata": {
        "id": "wK66_fvkxdyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Just do 5 items for speed. Change to 50 for actual experiment.\n",
        "for i in range(50):\n",
        "    item = test_dataset[i]\n",
        "    mix = item['mix']\n",
        "    my_hpss = MyHPSS(item['mix'])\n",
        "    hpss_estimates = my_hpss()\n",
        "\n",
        "    hpss_fg, hpss_bg = hpss_estimates\n",
        "    source_keys = list(item['sources'].keys())\n",
        "    estimates = {\n",
        "        'vocals': hpss_fg,\n",
        "        'bass+drums+other': hpss_bg\n",
        "    }\n",
        "\n",
        "    sources = [item['sources'][k] for k in source_keys]\n",
        "    estimates = [estimates[k] for k in source_keys]\n",
        "\n",
        "    evaluator = nussl.evaluation.BSSEvalScale(\n",
        "        sources, estimates, source_labels=source_keys\n",
        "    )\n",
        "    scores = evaluator.evaluate()\n",
        "    output_folder = Path(output_folder).absolute()\n",
        "    output_folder.mkdir(exist_ok=True)\n",
        "    output_file = output_folder / sources[0].file_name.replace('wav', 'json')\n",
        "    with open(output_file, 'w') as f:\n",
        "        json.dump(scores, f, indent=4)"
      ],
      "metadata": {
        "id": "-eR1viY9xBG9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "json_files = glob.glob(f\"*.json\")\n",
        "df = nussl.evaluation.aggregate_score_files(\n",
        "    json_files, aggregator=np.nanmedian)\n",
        "nussl.evaluation.associate_metrics(repet, df, test_dataset)\n",
        "report_card = nussl.evaluation.report_card(\n",
        "    df, report_each_source=True)\n",
        "print(report_card)"
      ],
      "metadata": {
        "id": "Vv_ZH_ARxhyF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "item = test_dataset[0]\n",
        "mix = item['mix']\n",
        "my_hpss = MyHPSS(item['mix'])\n",
        "hpss_estimates = my_hpss()\n",
        "\n",
        "hpss_fg, hpss_bg = hpss_estimates"
      ],
      "metadata": {
        "id": "eAma_pmaxo0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "item['sources']"
      ],
      "metadata": {
        "id": "eG5_3qs7zJIj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hpss_fg.embed_audio()\n",
        "# hpss_bg.embed_audio()"
      ],
      "metadata": {
        "id": "RVp8VKpKyPYt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Deep Learning Method"
      ],
      "metadata": {
        "id": "klxQQPk1RTV-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Prepare data"
      ],
      "metadata": {
        "id": "dr1286DoRW8l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AiivAuoFo2s_"
      },
      "outputs": [],
      "source": [
        "stft_params = nussl.STFTParams(window_length=512, hop_length=128, window_type='sqrt_hann')\n",
        "fg_path = \"~/.nussl/tutorial/train\"\n",
        "train_data = data.on_the_fly(stft_params, transform=None, fg_path=fg_path, num_mixtures=1000, coherent_prob=1.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LV2uyNTvo2tD"
      },
      "outputs": [],
      "source": [
        "fg_path = \"~/.nussl/tutorial/valid\"\n",
        "val_data = data.on_the_fly(stft_params, transform=None, fg_path=fg_path, num_mixtures=500)\n",
        "\n",
        "fg_path = \"~/.nussl/tutorial/test\"\n",
        "test_data = data.on_the_fly(stft_params, transform=None, fg_path=fg_path, num_mixtures=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Build model"
      ],
      "metadata": {
        "id": "SJhUhjhCRaoS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NGIgjSxvo2tL"
      },
      "outputs": [],
      "source": [
        "from nussl.ml.networks.modules import AmplitudeToDB, BatchNorm, RecurrentStack, Embedding\n",
        "from torch import nn\n",
        "import torch\n",
        "\n",
        "class MaskInference(nn.Module):\n",
        "    def __init__(self, num_features, num_audio_channels, hidden_size,\n",
        "                 num_layers, bidirectional, dropout, num_sources, \n",
        "                activation='sigmoid'):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.amplitude_to_db = AmplitudeToDB()\n",
        "        self.input_normalization = BatchNorm(num_features)\n",
        "        self.recurrent_stack = RecurrentStack(\n",
        "            num_features * num_audio_channels, hidden_size, \n",
        "            num_layers, bool(bidirectional), dropout\n",
        "        )\n",
        "        hidden_size = hidden_size * (int(bidirectional) + 1)\n",
        "        self.embedding = Embedding(num_features, hidden_size, \n",
        "                                   num_sources, activation, \n",
        "                                   num_audio_channels)\n",
        "        \n",
        "    def forward(self, data):\n",
        "        mix_magnitude = data # save for masking\n",
        "        \n",
        "        data = self.amplitude_to_db(mix_magnitude)\n",
        "        data = self.input_normalization(data)\n",
        "        data = self.recurrent_stack(data)\n",
        "        mask = self.embedding(data)\n",
        "        estimates = mix_magnitude.unsqueeze(-1) * mask\n",
        "        \n",
        "        output = {\n",
        "            'mask': mask,\n",
        "            'estimates': estimates\n",
        "        }\n",
        "        return output\n",
        "    \n",
        "    # Added function\n",
        "    @classmethod\n",
        "    def build(cls, num_features, num_audio_channels, hidden_size, \n",
        "              num_layers, bidirectional, dropout, num_sources, \n",
        "              activation='sigmoid'):\n",
        "        # Step 1. Register our model with nussl\n",
        "        nussl.ml.register_module(cls)\n",
        "        \n",
        "        # Step 2a: Define the building blocks.\n",
        "        modules = {\n",
        "            'model': {\n",
        "                'class': 'MaskInference',\n",
        "                'args': {\n",
        "                    'num_features': num_features,\n",
        "                    'num_audio_channels': num_audio_channels,\n",
        "                    'hidden_size': hidden_size,\n",
        "                    'num_layers': num_layers,\n",
        "                    'bidirectional': bidirectional,\n",
        "                    'dropout': dropout,\n",
        "                    'num_sources': num_sources,\n",
        "                    'activation': activation\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "        \n",
        "        \n",
        "        # Step 2b: Define the connections between input and output.\n",
        "        # Here, the mix_magnitude key is the only input to the model.\n",
        "        connections = [\n",
        "            ['model', ['mix_magnitude']]\n",
        "        ]\n",
        "        \n",
        "        # Step 2c. The model outputs a dictionary, which SeparationModel will\n",
        "        # change the keys to model:mask, model:estimates. The lines below \n",
        "        # alias model:mask to just mask, and model:estimates to estimates.\n",
        "        # This will be important later when we actually deploy our model.\n",
        "        for key in ['mask', 'estimates']:\n",
        "            modules[key] = {'class': 'Alias'}\n",
        "            connections.append([key, f'model:{key}'])\n",
        "        \n",
        "        # Step 2d. There are two outputs from our SeparationModel: estimates and mask.\n",
        "        # Then put it all together.\n",
        "        output = ['estimates', 'mask',]\n",
        "        config = {\n",
        "            'name': cls.__name__,\n",
        "            'modules': modules,\n",
        "            'connections': connections,\n",
        "            'output': output\n",
        "        }\n",
        "        # Step 3. Instantiate the model as a SeparationModel.\n",
        "        return nussl.ml.SeparationModel(config)\n",
        "\n",
        "nf = stft_params.window_length // 2 + 1\n",
        "nac = 1\n",
        "model = MaskInference.build(nf, nac, 50, 2, True, 0.3, 1, 'sigmoid')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JsGuNUK3o2tO"
      },
      "outputs": [],
      "source": [
        "from common.models import MaskInference\n",
        "\n",
        "nf = stft_params.window_length // 2 + 1\n",
        "nac = 1\n",
        "model = MaskInference.build(nf, nac, 50, 2, True, 0.3, 1, 'sigmoid')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gPSl5vfko2tR"
      },
      "outputs": [],
      "source": [
        "def train_step(engine, batch):\n",
        "    optimizer.zero_grad()\n",
        "    output = model(batch) # forward pass\n",
        "    loss = loss_fn(\n",
        "        output['estimates'],\n",
        "        batch['source_magnitudes']\n",
        "    )\n",
        "    \n",
        "    loss.backward() # backwards + gradient step\n",
        "    optimizer.step()\n",
        "    \n",
        "    loss_vals = {\n",
        "        'L1Loss': loss.item()\n",
        "    }\n",
        "    \n",
        "    return loss_vals # return the loss for bookkeeping."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Woaj2eeMo2tR"
      },
      "outputs": [],
      "source": [
        "def val_step(engine, batch):\n",
        "    with torch.no_grad():\n",
        "        output = model(batch) # forward pass\n",
        "    loss = loss_fn(\n",
        "        output['estimates'],\n",
        "        batch['source_magnitudes']\n",
        "    )    \n",
        "    loss_vals = {'L1Loss': loss.item()}\n",
        "    return loss_vals # return the loss for bookkeeping."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Training"
      ],
      "metadata": {
        "id": "-4Hc9UecRfvb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rxVQjuAjo2tR"
      },
      "outputs": [],
      "source": [
        "import nussl\n",
        "import torch\n",
        "from nussl.datasets import transforms as nussl_tfm\n",
        "from common.models import MaskInference\n",
        "from common import utils, data\n",
        "from pathlib import Path\n",
        "\n",
        "utils.logger()\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "MAX_MIXTURES = int(1e8) # We'll set this to some impossibly high number for on the fly mixing.\n",
        "\n",
        "stft_params = nussl.STFTParams(window_length=512, hop_length=128)\n",
        "\n",
        "tfm = nussl_tfm.Compose([\n",
        "    nussl_tfm.SumSources([['bass', 'drums', 'other']]),\n",
        "    nussl_tfm.MagnitudeSpectrumApproximation(),\n",
        "    nussl_tfm.IndexSources('source_magnitudes', 1),\n",
        "    nussl_tfm.ToSeparationModel(),\n",
        "])\n",
        "\n",
        "train_folder = \"~/.nussl/tutorial/train\"\n",
        "val_folder = \"~/.nussl/tutorial/valid\"\n",
        "\n",
        "train_data = data.on_the_fly(stft_params, transform=tfm, \n",
        "    fg_path=train_folder, num_mixtures=MAX_MIXTURES, coherent_prob=1.0)\n",
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "    train_data, num_workers=1, batch_size=10)\n",
        "\n",
        "val_data = data.on_the_fly(stft_params, transform=tfm, \n",
        "    fg_path=val_folder, num_mixtures=10, coherent_prob=1.0)\n",
        "val_dataloader = torch.utils.data.DataLoader(\n",
        "    val_data, num_workers=1, batch_size=10)\n",
        "\n",
        "nf = stft_params.window_length // 2 + 1\n",
        "model = MaskInference.build(nf, 1, 50, 1, True, 0.0, 1, 'sigmoid')\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "loss_fn = nussl.ml.train.loss.L1Loss()\n",
        "\n",
        "def train_step(engine, batch):\n",
        "    optimizer.zero_grad()\n",
        "    output = model(batch) # forward pass\n",
        "    loss = loss_fn(\n",
        "        output['estimates'],\n",
        "        batch['source_magnitudes']\n",
        "    )\n",
        "    \n",
        "    loss.backward() # backwards + gradient step\n",
        "    optimizer.step()\n",
        "    \n",
        "    loss_vals = {\n",
        "        'L1Loss': loss.item(),\n",
        "        'loss': loss.item()\n",
        "    }\n",
        "    \n",
        "    return loss_vals\n",
        "\n",
        "def val_step(engine, batch):\n",
        "    with torch.no_grad():\n",
        "        output = model(batch) # forward pass\n",
        "    loss = loss_fn(\n",
        "        output['estimates'],\n",
        "        batch['source_magnitudes']\n",
        "    )    \n",
        "    loss_vals = {\n",
        "        'L1Loss': loss.item(), \n",
        "        'loss': loss.item()\n",
        "    }\n",
        "    return loss_vals\n",
        "\n",
        "# Create the engines\n",
        "trainer, validator = nussl.ml.train.create_train_and_validation_engines(\n",
        "    train_step, val_step, device=DEVICE\n",
        ")\n",
        "\n",
        "# We'll save the output relative to this notebook.\n",
        "output_folder = Path('.').absolute()\n",
        "\n",
        "# Adding handlers from nussl that print out details about model training\n",
        "# run the validation step, and save the models.\n",
        "nussl.ml.train.add_stdout_handler(trainer, validator)\n",
        "nussl.ml.train.add_validate_and_checkpoint(output_folder, model, \n",
        "    optimizer, train_data, trainer, val_dataloader, validator)\n",
        "\n",
        "trainer.run(\n",
        "    train_dataloader, \n",
        "    epoch_length=300, \n",
        "    max_epochs=1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Testing"
      ],
      "metadata": {
        "id": "xeFz2P31RjJU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cuyRWrONo2tS"
      },
      "outputs": [],
      "source": [
        "separator = nussl.separation.deep.DeepMaskEstimation(\n",
        "    nussl.AudioSignal(), model_path='checkpoints/best.model.pth',\n",
        "    device=DEVICE,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sIZ8sCRFo2tT"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "tfm = nussl_tfm.Compose([\n",
        "    nussl_tfm.SumSources([['bass', 'drums', 'other']]),\n",
        "])\n",
        "test_dataset = nussl.datasets.MUSDB18(subsets=['test'], transform=tfm)\n",
        "\n",
        "# Just do 5 items for speed. Change to 50 for actual experiment.\n",
        "for i in range(5):\n",
        "    item = test_dataset[i]\n",
        "    separator.audio_signal = item['mix']\n",
        "    estimates = separator()\n",
        "\n",
        "    source_keys = list(item['sources'].keys())\n",
        "    estimates = {\n",
        "        'vocals': estimates[0],\n",
        "        'bass+drums+other': item['mix'] - estimates[0]\n",
        "    }\n",
        "\n",
        "    sources = [item['sources'][k] for k in source_keys]\n",
        "    estimates = [estimates[k] for k in source_keys]\n",
        "\n",
        "    evaluator = nussl.evaluation.BSSEvalScale(\n",
        "        sources, estimates, source_labels=source_keys\n",
        "    )\n",
        "    scores = evaluator.evaluate()\n",
        "    output_folder = Path(output_folder).absolute()\n",
        "    output_folder.mkdir(exist_ok=True)\n",
        "    output_file = output_folder / sources[0].file_name.replace('wav', 'json')\n",
        "    with open(output_file, 'w') as f:\n",
        "        json.dump(scores, f, indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z82y5nZyo2tT"
      },
      "outputs": [],
      "source": [
        "\n",
        "json_files = glob.glob(f\"*.json\")\n",
        "df = nussl.evaluation.aggregate_score_files(\n",
        "    json_files, aggregator=np.nanmedian)\n",
        "nussl.evaluation.associate_metrics(separator.model, df, test_dataset)\n",
        "report_card = nussl.evaluation.report_card(\n",
        "    df, report_each_source=True)\n",
        "print(report_card)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Copy of Test and Deep Learning Method",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}